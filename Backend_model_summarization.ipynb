{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7fAOHzR_ltZ"
      },
      "source": [
        "Reference - article - https://www.analyticsvidhya.com/blog/2022/01/youtube-summariser-mini-nlp-project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiYQ0n5lpMEr",
        "outputId": "16e2afa4-36e8-4d3d-d9ec-3fc6a52aee5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.6.0)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from youtube-transcript-api) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->youtube-transcript-api) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->youtube-transcript-api) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->youtube-transcript-api) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->youtube-transcript-api) (1.26.9)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install youtube-transcript-api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s-1ZyK9cmBC_"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import youtube_transcript_api\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import sklearn \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3ERcWJHy8ii",
        "outputId": "80310e60-cbba-4887-9129-d1d4069da1dc"
      },
      "outputs": [],
      "source": [
        "! pip install pytube -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lFSUrHEiz9fP"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBcLa4bC2bcF"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall pyarrow\n",
        "# !pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWRj6msczyh8",
        "outputId": "d675ae4b-700f-45a7-9b82-9e117d998eee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install huggingsound -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuzBmx-jz09-"
      },
      "outputs": [],
      "source": [
        "from huggingsound import SpeechRecognitionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lBWSF4uz64O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7oQRd-v8y_ar",
        "outputId": "5153663e-d4ad-43c9-a939-eae2cd6168a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTTeQAe00HXB"
      },
      "outputs": [],
      "source": [
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-6YJdwW0TqP"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf8JC6PK6Vw0"
      },
      "outputs": [],
      "source": [
        "link = \"https://www.youtube.com/watch?v=Y8Tko2YC5hA\" #with subtitle\n",
        "# link = \"https://www.youtube.com/watch?v=8ZT_Q_B_qbM\" age-restricted\n",
        "# link = \"https://youtu.be/RIJ2Jclv9Dg?si=SPwk1Dhw3W2EeMwe\" # without subtitle\n",
        "unique_id = link.split(\"=\")[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L1ex41vB7gW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gKPtXTCmQtA"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import TranscriptsDisabled\n",
        "\n",
        "try:\n",
        "  sub = YouTubeTranscriptApi.get_transcript(unique_id)\n",
        "  subtitle = \" \".join([x['text'] for x in sub])\n",
        "except TranscriptsDisabled as e:\n",
        "  print(\"Subtitles are disabled for this video. You may need to handle this case differently.\")\n",
        "  # Your alternative code or error handling mechanism goes here\n",
        "\n",
        "  # Download YouTube Video's Audio\n",
        "  yt = YouTube(link)\n",
        "  # Filter and get the first audio-only stream in mp4 format\n",
        "  audio_stream = yt.streams.filter(only_audio=True, file_extension='mp4').first()\n",
        "\n",
        "  # Download the audio stream\n",
        "  audio_stream.download(filename='ytaudio.mp4')\n",
        "  ! ffmpeg -i ytaudio.mp4 -acodec pcm_s16le -ar 16000 ytaudio.wav\n",
        "\n",
        "  # English ASR with HuggingSound\n",
        "  model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\", device = device)\n",
        "\n",
        "  # Audio Chunking\n",
        "  input_file = '/content/ytaudio.wav'\n",
        "  print(librosa.get_samplerate(input_file))\n",
        "\n",
        "  # Stream over 30 seconds chunks rather than load the full file\n",
        "  stream = librosa.stream(\n",
        "      input_file,\n",
        "      block_length=30,\n",
        "      frame_length=16000,\n",
        "      hop_length=16000\n",
        "  )\n",
        "  for i,speech in enumerate(stream):\n",
        "    sf.write(f'{i}.wav', speech, 16000)\n",
        "\n",
        "  # Audio Transcription / ASR / Speech to Text\n",
        "  audio_path =[]\n",
        "  for a in range(i+1):\n",
        "    audio_path.append(f'/content/{a}.wav')\n",
        "  transcriptions = model.transcribe(audio_path)\n",
        "  subtitle = ' '\n",
        "  for item in transcriptions:\n",
        "    subtitle += ''.join(item['transcription'])\n",
        "  len(subtitle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgKT-V6dnEr2"
      },
      "source": [
        "# **Summarization using BART**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgMhF_TWnJWJ",
        "outputId": "0ca7119c-b82b-43cc-956b-c822376ebdcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxUS9DFJnLs8"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw3CuOpGd37M",
        "outputId": "497be746-cc90-4736-b43e-961ac8e423eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5zhxS93a_St",
        "outputId": "a8f9a2f2-6eac-4f6b-8c0b-d58899bd0adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is the world's fastest growing and most popular programming language. People from different disciplines use Python for a variety of different tasks, such as data analysis and visualization, artificial intelligence and machine learning. Python is a multi-purpose language with a simple, clean, and beginner-friendly syntax. Python developers earn a whopping 116,000 dollars a year. Mosh has a couple of Python tutorials for beginners.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Mr-Vicky-01/Bart-Finetuned-conversational-summarization\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Mr-Vicky-01/Bart-Finetuned-conversational-summarization\")\n",
        "\n",
        "def generate_summary(text):\n",
        "    inputs = tokenizer([text], max_length=102400, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], max_new_tokens=10000, do_sample=False)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "text_to_summarize = subtitle\n",
        "summary = generate_summary(text_to_summarize)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTDdqhUGd6sT",
        "outputId": "b6da6314-227d-436c-8158-13233f0e9148"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is the world's fastest growing and most popular programming language.\n",
            "People from different disciplines use Python for a variety of different tasks, such as data analysis and visualization, artificial intelligence and machine learning.\n",
            "Python is a multi-purpose language with a simple, clean, and beginner-friendly syntax.\n",
            "Python developers earn a whopping 116,000 dollars a year.\n",
            "Mosh has a couple of Python tutorials for beginners.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Mr-Vicky-01/Bart-Finetuned-conversational-summarization\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Mr-Vicky-01/Bart-Finetuned-conversational-summarization\")\n",
        "\n",
        "def generate_summary(text):\n",
        "    inputs = tokenizer([text], max_length=102400, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], max_new_tokens=10000, do_sample=False)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "text_to_summarize = subtitle\n",
        "summary = generate_summary(text_to_summarize)\n",
        "\n",
        "# Split the summary into individual sentences\n",
        "sentences = nltk.sent_tokenize(summary)\n",
        "\n",
        "# Print each sentence on a new line\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H5NVccynOLu"
      },
      "outputs": [],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yRTBEodnQcO",
        "outputId": "923036ea-7fc8-4b51-85fe-e57628f7674d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "input_tensor = tokenizer.encode( subtitle, return_tensors=\"pt\", max_length=512)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9wMoezfnSvG",
        "outputId": "d5acf552-da63-41fb-a6cd-9c32880d89d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    2,     0, 17781,    10,  4069,     9,  5886, 31538,   895,  9611,\n",
              "         18711,     8,  8276,    59,    80,   722,    71,   110,  5573,  5820,\n",
              "             4,    83, 23611,    19,   143, 17145,  4297,  1334, 17589,  5806,\n",
              "           196,    50,  7756,   873, 12158,   817,    13,    10,   372, 17687,\n",
              "             4,   318,    47,   214, 10759,  1588,  1070,  1095,   409,    31,\n",
              "         31130,     8,    62,    13,    41, 15162,  1386,     4,    83,   543,\n",
              "            12,  3983,  6691,  8380, 35455,    19,   455,  5886,   313,   293,\n",
              "             8,  7983,  9649,   118,   181,  3119,    16,    67,    10,   205,\n",
              "         17687,     4,  1599,    75,  4309,     7, 17687,    77,    47,   214,\n",
              "            15,     5,   300,  5113,    10, 17687,  3298,  4740,   455,     9,\n",
              "         15092,     8,  3841,    12, 30929,    50,    10, 10894,    12,  4901,\n",
              "          4066,    11,  8276,     4,  6893,    13,    65,    19,    23,   513,\n",
              "           799, 14080,     9,  8276,     8,   292, 14080,     9,  5886,     4,\n",
              "             2]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs_tensor = model.generate(input_tensor, max_length=160, min_length=120, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "outputs_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVhZuWFinWS_"
      },
      "outputs": [],
      "source": [
        "# print(tokenizer.decode(outputs_tensor[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzmCDtscjGJX",
        "outputId": "96635222-d58d-408a-ffa9-9a583efc26dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "</s><s>Have a combination of fat carbahydrates and protein about two hours after your las meal\n",
            "A banana with any nutbutter ulmoned or pinabutter makes for a great snack\n",
            "If you're constipated stay away from bananas and up for an apple instead\n",
            "A hard-boiled egg mashed with full fat manes and miniholi pita is also a good snack\n",
            "Don't forget to snack when you're on the gotake a snack baggy full of nuts and dry-fruit or a nutrition-bar rich in protein\n",
            "Look for one with at least eight grams of protein and five grams of fat\n",
            "</s>\n"
          ]
        }
      ],
      "source": [
        "output_text = tokenizer.decode(outputs_tensor[0])\n",
        "\n",
        "# Split the output text into multiple lines based on a specific character or length\n",
        "# For example, splitting at every period ('.') or after a certain number of characters\n",
        "lines = output_text.split('.')\n",
        "# Or split by a certain length\n",
        "# lines = [output_text[i:i+80] for i in range(0, len(output_text), 80)]\n",
        "\n",
        "# Print each line separately\n",
        "for line in lines:\n",
        "    print(line.strip())  # strip to remove extra spaces or newlines\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
